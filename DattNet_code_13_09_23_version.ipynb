{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db12374-8207-4468-8fb3-862b50b48c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Subset, Dataset\n",
    "from PIL import Image\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import io\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd5f76-92b1-4f12-b4c4-ba734783718a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **DattNet section:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadab4e-2ae6-4bf1-9f90-facbf25dd6b7",
   "metadata": {},
   "source": [
    "**DattNet Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b13137-5243-41a0-ad03-c4c36359cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DattNet(nn.Module):\n",
    "    def __init__(self, pic_width, m_patterns, input_shape):\n",
    "        super(DattNet, self).__init__()\n",
    "        self.m_patterns = m_patterns\n",
    "        self.ims = pic_width  # must be even number\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = input_shape[2]\n",
    "        # self.filter_depth = filter_depth\n",
    "        # self.kernel_size = kernel_size\n",
    "        # self.classes = classes\n",
    "        self.c_i7 = 768\n",
    "\n",
    "        # Datt Net\n",
    "        self.fc_layer_1 = nn.Linear(self.m_patterns, 4096)\n",
    "        self.fc_layer_2 = nn.Linear(4096, 16384)\n",
    "        self.diconv_layer_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding='same', dilation=2),\n",
    "            nn.MaxPool2d((2, 2)))\n",
    "        self.blue_block_4 = BlueBlock(16, 26)\n",
    "        self.blue_block_5 = BlueBlock(26, 31)\n",
    "        self.blue_block_6 = BlueBlock(31, 33)\n",
    "        self.blue_block_7 = BlueBlock(33, 34)\n",
    "        self.blue_block_8 = BlueBlock(34, 35)\n",
    "        self.blue_block_9 = BlueBlock(35, 36)\n",
    "        self.dense_block_10 = DenseBlock(36, 36)\n",
    "        self.semi_red_block_11 = SemiRedAttBlock(36, 36, 36, 36, 36)\n",
    "        self.semi_red_block_12 = SemiRedAttBlock(36, 35, 36, 35, 36)\n",
    "        self.red_block_13 = RedAttBlock(36, 34, 36, 34, 36)\n",
    "        self.red_block_14 = RedAttBlock(36, 33, 36, 33, 36)\n",
    "        self.red_block_15 = RedAttBlock(36, 31, 36, 31, 36)\n",
    "        self.red_block_16 = RedAttBlock(36, 26, 36, 26, 36)\n",
    "        self.layer_17 = nn.Sequential(nn.Conv2d(in_channels=36, out_channels=36, kernel_size=3, padding='same'),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Upsample(scale_factor=2),\n",
    "                                      nn.Conv2d(in_channels=36, out_channels=36, kernel_size=3, padding='same'),\n",
    "                                      nn.ReLU(inplace=True))\n",
    "        self.layer_18 = nn.Sequential(nn.Conv2d(in_channels=36, out_channels=1, kernel_size=1, padding='same'),\n",
    "                                      nn.ReLU(inplace=True))\n",
    "        self.nlt_19 = nn.Sequential(nn.BatchNorm2d(1),\n",
    "                                    nn.Linear(128, 128))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layer_1(x)\n",
    "        x = self.fc_layer_2(x)\n",
    "        x = x.reshape(-1, 1, 128, 128)\n",
    "        x = self.diconv_layer_3(x)\n",
    "        x4 = self.blue_block_4(x)\n",
    "        x5 = self.blue_block_5(x4)\n",
    "        x6 = self.blue_block_6(x5)\n",
    "        x7 = self.blue_block_7(x6)\n",
    "        x8 = self.blue_block_8(x7)\n",
    "        x9 = self.blue_block_9(x8)\n",
    "        x = self.dense_block_10(x9)\n",
    "        x = self.semi_red_block_11(x, x9)\n",
    "        x = self.semi_red_block_12(x, x8)\n",
    "        x = self.red_block_13(x, x7)\n",
    "        x = self.red_block_14(x, x6)\n",
    "        x = self.red_block_15(x, x5)\n",
    "        x = self.red_block_16(x, x4)\n",
    "        x = self.layer_17(x)\n",
    "        x = self.layer_18(x)\n",
    "        x = self.nlt_19(x)\n",
    "        return x\n",
    "\n",
    "    def first_block(self, x):\n",
    "        batch_size, num_feats = x.shape\n",
    "        self.int_fc1 = nn.Linear(num_feats, 32 * 32)\n",
    "        x = F.relu(self.int_fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.int_fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.conv_block1(x.view(-1, 1, 2 * self.ims, 2 * self.ims)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.conv_block2(x))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def fork_block(self, x):\n",
    "        # path 1\n",
    "        x1 = self.res_block(x)\n",
    "\n",
    "        # path 2\n",
    "        x2 = self.maxpool2(x)\n",
    "        x2 = self.res_block(x2)\n",
    "        x2 = self.upsample(x2)\n",
    "\n",
    "        # path 3\n",
    "        x3 = self.maxpool4(x)\n",
    "        x3 = self.res_block(x3)\n",
    "        x3 = self.upsample(x3)\n",
    "        x3 = self.upsample(x3)\n",
    "\n",
    "        # path 4\n",
    "        x4 = self.maxpool8(x)\n",
    "        x4 = self.res_block(x4)\n",
    "        x4 = self.upsample(x4)\n",
    "        x4 = self.upsample(x4)\n",
    "        x4 = self.upsample(x4)\n",
    "\n",
    "        concat_x = torch.cat((x1, x2, x3, x4), 1)\n",
    "        return concat_x\n",
    "\n",
    "    def res_block(self, x):\n",
    "        \"\"\" 4 blue res block, fit to all paths\"\"\"\n",
    "        for _ in range(4):\n",
    "            y = F.relu(self.conv_res(x))\n",
    "            f_x = F.relu(self.conv_res(y))\n",
    "            x = F.relu(x + f_x)\n",
    "        return x\n",
    "\n",
    "    def final_block(self, x):\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = F.relu(self.conv_block3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.conv_block4(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.conv_block5(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.last_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06033332-7b94-409f-b91a-79ea61ae290e",
   "metadata": {},
   "source": [
    "**Block Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661ef081-00c0-4072-ba39-1b06b238d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.layer = nn.Sequential(nn.BatchNorm2d(c_in),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(in_channels=c_in, out_channels=c_in, kernel_size=5, padding='same', dilation=2))\n",
    "        self.transition_layers = nn.Sequential(nn.BatchNorm2d(c_in),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(in_channels=c_in, out_channels=c_in, kernel_size=1, padding='same', dilation=2),\n",
    "                                    nn.Dropout(0.05),\n",
    "                                    nn.AvgPool2d(2))\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x2 = self.layer(x1)\n",
    "\n",
    "        x3 = self.layer(x1 + x2)\n",
    "\n",
    "        x4 = self.layer(x1 + x2 + x3)\n",
    "\n",
    "        x = x1 + x2 + x3 + x4\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2fceea-4ad5-4196-9c2b-243f26bdbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlueBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(BlueBlock, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.dense_block = DenseBlock(c_in, c_in)\n",
    "        self.transition_layers = nn.Sequential(nn.BatchNorm2d(c_in),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=1, dilation=2),\n",
    "                                    nn.Dropout(0.05),\n",
    "                                    nn.AvgPool2d(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_block(x)\n",
    "        x = self.transition_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19241e07-717b-4efe-891a-d3d6ff3baa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_block(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(Attention_block, self).__init__()\n",
    "        self.params = {'F_g': F_g, 'F_l': F_l, 'F_int': F_int}\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49e3646-8264-4c97-afc8-912d915ccaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedAttBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int, c_in, c_out):\n",
    "        super(RedAttBlock, self).__init__()\n",
    "        self.params = {'F_g': F_g, 'F_l': F_l, 'F_int': F_int, 'c_in': c_in, 'c_out': c_out}\n",
    "        self.att_gate = Attention_block(F_g, F_l, F_int)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_in, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.dence_block = DenseBlock(c_out, c_out)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        x = self.att_gate(g, x)\n",
    "        x = self.layers(x)\n",
    "        x = self.dence_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d53cba-a075-4867-b623-48fcc7a53633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiRedAttBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int, c_in, c_out):\n",
    "        super(SemiRedAttBlock, self).__init__()\n",
    "        self.params = {'F_g': F_g, 'F_l': F_l, 'F_int': F_int, 'c_in': c_in, 'c_out': c_out}\n",
    "        self.att_gate = Attention_block(F_g, F_l, F_int)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_in, kernel_size=1, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=1, padding='same'),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.dence_block = DenseBlock(c_out, c_out)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        x = self.att_gate(g, x)\n",
    "        x = self.layers(x)\n",
    "        x = self.dence_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83e780-1532-4392-9919-0aa777d6db96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **DataFunctions section:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f4eaca-253a-4f0e-9c16-ee022a085d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(generate, log_path, batch_size, pic_width, prc_patterns, m_patterns, num_train_coco, num_train_mnist,\n",
    "             num_test_coco, num_test_mnist, n_gray_levels, data_sets):\n",
    "    \"\"\" Load data if the parameters agree with some saved dataset.\n",
    "        Create the data otherwise by those parameters and saved it. \"\"\"\n",
    "    \n",
    "    train_set_file_name = f\"Loaders/train_loader_trNum_C{num_train_coco}_M{num_train_mnist}\" + \\\n",
    "                          f\"_mp{prc_patterns}_ngl{n_gray_levels}.pickle\"\n",
    "    test_set_file_name = f\"Loaders/test_loader_tsNum_C{num_test_coco}_M{num_test_mnist}\" + \\\n",
    "                         f\"_mp{prc_patterns}_ngl{n_gray_levels}.pickle\"\n",
    "    \n",
    "    storage_client = storage.Client()    # create a client to interact with Google Cloud Storage\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")   # set the bucket\n",
    "    \n",
    "    # if the loaders exists, don't generate - unless generate is True\n",
    "    if (bucket.blob(train_set_file_name).exists() and bucket.blob(test_set_file_name).exists()) and (not generate):\n",
    "        start = time.time()\n",
    "        print(\"loading existing data loaders\")   # print message for debug\n",
    "        train_loader, test_loader = load_generated_data(train_set_file_name, test_set_file_name, batch_size, bucket)\n",
    "        end = time.time()\n",
    "        data_time_message = f\"Loading the data took : {round(end - start)} sec\"\n",
    "        patterns = []\n",
    "    else:\n",
    "        start = time.time()\n",
    "        train_data, test_data = load_data(data_sets, batch_size, pic_width, num_train_coco,\n",
    "                                          num_train_mnist, num_test_coco, num_test_mnist)\n",
    "        train_detector_data, test_detector_data, patterns = generate_data(train_data, test_data, pic_width, m_patterns,\n",
    "                                                                          batch_size, n_gray_levels, patterns='new')\n",
    "        print(f\"finished generating. starting to save the loaders\")   # print message for debug\n",
    "        save_generated_data(train_set_file_name, train_detector_data, test_set_file_name,\n",
    "                            test_detector_data, bucket)\n",
    "        \n",
    "        # prepare data loaders\n",
    "        train_loader = torch.utils.data.DataLoader(train_detector_data, batch_size=batch_size)\n",
    "        test_loader = torch.utils.data.DataLoader(test_detector_data, batch_size=batch_size)\n",
    "        print(f\"starting to train :)\")   # print message for debug\n",
    "        \n",
    "        end = time.time()\n",
    "        if round(end - start) > 3600:    # if took more than an hour\n",
    "            data_time_message = f\"Generating the data took : {(round(end - start)) / 3600} hours\"\n",
    "        else:\n",
    "            data_time_message = f\"Generating the data took : {(round(end - start)) / 60} mins\"\n",
    "\n",
    "    return train_loader, test_loader, data_time_message, patterns\n",
    "\n",
    "\n",
    "# TODO: when loading, the training fails for sweeps (for regular runs it works)\n",
    "def load_generated_data(train_set_file_name, test_set_file_name, batch_size, bucket):\n",
    "    \"\"\" if data loaders exists - load them. \"\"\"\n",
    "    in_train_file = io.BytesIO(bucket.blob(train_set_file_name).download_as_bytes())\n",
    "    in_test_file = io.BytesIO(bucket.blob(test_set_file_name).download_as_bytes())\n",
    "        \n",
    "    train_dataset = pickle.load(in_train_file)\n",
    "    test_dataset = pickle.load(in_test_file)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d89eb-7511-4e5c-a127-d9ddc7e677b7",
   "metadata": {},
   "source": [
    "**Generate new data loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef19d69b-a4a2-4546-9daf-21c0d8e320b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(data_sets, batch_size, pic_width, num_train_coco, num_train_mnist, num_test_coco, num_test_mnist):\n",
    "    train_data_coco, train_data_div2k, train_data_mnist = [], [], []\n",
    "    test_data_coco, test_data_div2k, test_data_mnist = [], [], []\n",
    "    if 'coco' in data_sets:\n",
    "        train_data_coco, test_data_coco = load_data_coco(batch_size, pic_width, num_train_coco, num_test_coco)\n",
    "    if 'div2k' in data_sets:\n",
    "        train_data_div2k, test_data_div2k = load_data_div2k(batch_size, pic_width, num_train_coco, num_test_coco)\n",
    "    if 'mnist' in data_sets:\n",
    "        train_data_mnist, test_data_mnist = load_data_mnist(batch_size, pic_width, num_train_mnist, num_test_mnist)\n",
    "    train_data = [train_data_coco, train_data_div2k, train_data_mnist]\n",
    "    test_data = [test_data_coco, test_data_div2k, test_data_mnist]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def generate_data(train_data, test_data, pic_width, m_patterns, batch_size, n_gray_levels, patterns):\n",
    "    \"\"\" Get 2 datasets (train & test) of images.\n",
    "        Return 2 data loaders (train & test) of simulated detector data of the images (GI samples).\n",
    "        patterns = 'new' will get random light patterns. Else it will use the patterns from the input.\"\"\"\n",
    "    if patterns == 'new':\n",
    "        patterns = define_m_random_patterns(pic_width, m_patterns)\n",
    "    train_detector_data, test_detector_data = create_detector_data_for_multidatasets(train_data, test_data, patterns,\n",
    "                                                                                     pic_width, n_gray_levels, batch_size)\n",
    "    return train_detector_data, test_detector_data, patterns\n",
    "        \n",
    "\n",
    "# TODO: fix memory issues in 2nd/3rd runs of a sweep when trying to save the datasets\n",
    "def save_generated_data(train_set_file_name, train_data, test_set_file_name, test_data, bucket):\n",
    "    # serialize the train_loader object to a binary file in memory, then write the it to a blob in the bucket\n",
    "    serialized_train_loader = pickle.dumps(train_data)\n",
    "    bucket.blob(train_set_file_name).upload_from_string(serialized_train_loader, content_type='application/octet-stream')\n",
    "    \n",
    "    serialized_test_loader = pickle.dumps(test_data)\n",
    "    bucket.blob(test_set_file_name).upload_from_string(serialized_test_loader, content_type='application/octet-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfb9dfc-f258-491e-8df9-b16efd06ac2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom dataset class to load coco images from the bucket\n",
    "class CustomImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        storage_client = storage.Client()\n",
    "        self.bucket_name = \"our_train_test_data\"\n",
    "        self.bucket = storage_client.get_bucket(self.bucket_name)\n",
    "        \n",
    "        self.files = self.get_files_from_bucket(self.root)\n",
    "    \n",
    "    def get_files_from_bucket(self, directory):\n",
    "        prefix = f\"{directory}/\"\n",
    "        blobs = self.bucket.list_blobs(prefix=prefix)\n",
    "        files = [blob.name for blob in blobs if not blob.name.endswith('/')]  # filter out directories\n",
    "        return files\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.files[index]\n",
    "        blob = self.bucket.blob(file_path)\n",
    "        img = Image.open(io.BytesIO(blob.download_as_bytes())).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    \n",
    "def load_data_coco(batch_size, pic_width, num_train_samples, num_test_samples):\n",
    "    \"\"\" Load COCO images from the folder.\n",
    "        Return 2 datasets variables contained images - train and test - with the asked lengths.\"\"\"\n",
    "\n",
    "    train_images_path = 'data/coco-2017/all_data/train'\n",
    "    test_images_path = 'data/coco-2017/all_data/test'\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize((pic_width, pic_width)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Grayscale(num_output_channels=1),\n",
    "                                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                                    lambda x: x.float()])\n",
    "\n",
    "    # load the datasets from the bucket\n",
    "    train_data = CustomImageFolder(train_images_path, transform=transform)\n",
    "    test_data = CustomImageFolder(test_images_path, transform=transform)\n",
    "    \n",
    "    # slice the data\n",
    "    train_data = Subset(train_data, np.arange(num_train_samples))\n",
    "    test_data = Subset(test_data, np.arange(num_test_samples))\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d3010f-9883-4c94-a35a-fb0ba442f1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_mnist(batch_size, pic_width, num_train_mnist, num_test_mnist):\n",
    "    transform = transforms.Compose([transforms.Resize((pic_width, pic_width)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                    lambda x: x > 0,\n",
    "                                    lambda x: x.float()])  # convert data to torch.FloatTensor\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")\n",
    "    \n",
    "    train_data = datasets.MNIST(root='data', train=True, download=False, transform=transform)\n",
    "    test_data = datasets.MNIST(root='data', train=False, download=False, transform=transform)\n",
    "    \n",
    "    # slice the data if num is smaller than max\n",
    "    if num_train_mnist < 60000:\n",
    "        train_data = Subset(train_data, np.arange(num_train_mnist))\n",
    "    if num_test_mnist < 10000:\n",
    "        test_data = Subset(test_data, np.arange(num_test_mnist))\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad0a417b-dd08-45d8-ab0f-9b35e09a7459",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is not used - we don't have div2k images in the bucket\n",
    "def load_data_div2k(batch_size, pic_width, num_train_samples, num_test_samples):\n",
    "    \"\"\" Load div2k images from the folder.\n",
    "        Return 2 datasets variables contained images - train and test - with the asked lengths.\"\"\"\n",
    "\n",
    "    train_images_path = r'C:\\Users\\user\\Desktop\\Projects\\DattNet\\data\\div2k\\DIV2K_train_HR'\n",
    "    test_images_path = r'C:\\Users\\user\\Desktop\\Projects\\DattNet\\data\\div2k\\DIV2K_valid_HR'\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize((pic_width, pic_width)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Grayscale(num_output_channels=1),\n",
    "                                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                                    lambda x: x.float()])  #\n",
    "\n",
    "    train_data = datasets.ImageFolder(train_images_path, transform=transform)\n",
    "    test_data = datasets.ImageFolder(test_images_path, transform=transform)\n",
    "\n",
    "    # slice the data\n",
    "    train_data = Subset(train_data, np.arange(num_train_samples))\n",
    "    test_data = Subset(test_data, np.arange(num_test_samples))\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9040fc2f-211a-41ac-a0b1-f2a47b73d0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_m_random_patterns(pic_width, m):\n",
    "    \"\"\" define the light patterns\"\"\"\n",
    "    patterns = torch.rand(m, pic_width, pic_width)\n",
    "    return patterns\n",
    "\n",
    "\n",
    "def create_detector_data_for_multidatasets(train_data, test_data, patterns, pic_width, n_gray_levels, batch_size):\n",
    "    \"\"\" Get 2 datasets (train & test) of images and light patterns.\n",
    "        Return 2 tensors (train & test) of couples of [GI_sample, low_gray_image]\"\"\"\n",
    "    train_detector_data, test_detector_data = [], []\n",
    "    \n",
    "    for train_set, test_set in zip(train_data, test_data):\n",
    "        cur_train_detector_data = create_detector_data(train_set, patterns, pic_width, n_gray_levels, batch_size)   \n",
    "        cur_test_detector_data = create_detector_data(test_set, patterns, pic_width, n_gray_levels, batch_size) \n",
    "        \n",
    "        train_detector_data.extend(cur_train_detector_data)\n",
    "        test_detector_data.extend(cur_test_detector_data)\n",
    "    \n",
    "    return train_detector_data, test_detector_data\n",
    "\n",
    "\n",
    "# This function runs seperately for each dataset - coco/mnist and for train/test,\n",
    "# and calculates per batches for efficiency\n",
    "def create_detector_data(data_set, patterns, pic_width, n_gray_levels, batch_size):\n",
    "    \"\"\" Get a datasets (train/test) of images and light patterns.\n",
    "        Return a tensor (train/test) of couples of [GI_sample, low_gray_image]\"\"\"\n",
    "    detector_data = []\n",
    "    for batch_start in range(0, len(data_set), batch_size):\n",
    "        start = time.time()    # for print message after each batch\n",
    "        batch_end = min(batch_start + batch_size, len(data_set))\n",
    "        batch_indices = list(range(batch_start, batch_end))\n",
    "        batch = Subset(data_set, batch_indices)\n",
    "        \n",
    "        batch_output = []\n",
    "        for sample in batch:\n",
    "            image = sample[0].view(pic_width, pic_width).to(torch.float32)\n",
    "            low_gray_image = hist_equalization(image, n_gray_levels)\n",
    "            detector_output = sample_after_patterns(low_gray_image, patterns).clone().detach()\n",
    "            batch_output.append([detector_output, torch.flatten(low_gray_image)])\n",
    "\n",
    "        detector_data.extend(batch_output)   # extend to flatten the batch_output\n",
    "        print(f\"{time.time()-start}:\\t\\tfinished a batch\")   # print message for debug\n",
    "\n",
    "    return detector_data\n",
    "\n",
    "\n",
    "def sample_after_patterns(image, patterns):\n",
    "    \"\"\" Simulate the detector. Get one image and return GI output from the patterns.\"\"\"\n",
    "    patterns_tensor = patterns.to(image.device)\n",
    "    detector_output = torch.zeros(len(patterns), device=image.device)\n",
    "\n",
    "    for i in range(len(patterns)):\n",
    "        image_after_mask = image * patterns_tensor[i, None, :, :]\n",
    "        detector_output[i] = torch.sum(image_after_mask)\n",
    "    \n",
    "    return detector_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba2c43-033a-4651-826f-64bfad3b9d56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **LogFunctions section:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17024360-881c-44ae-965f-fb098d828f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_run_info_to_log(batch_size, pic_width, prc_patterns, n_gray_levels, m_patterns, initial_lr, div_factor_lr,\n",
    "                          num_dif_lr, n_epochs, num_train_coco, num_train_mnist, num_test_coco, num_test_mnist,\n",
    "                          lr_vector, epochs_vector, run_name, TRAIN_BY, folder_path='Logs'):\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "    log_name = f\"Log_{dt_string}_prc_{prc_patterns}.log\"\n",
    "    print(f'Name of log file: {log_name}')\n",
    "    log_path = folder_path +'/'+ log_name\n",
    "    logging.basicConfig(filename=log_path, format='%(asctime)s %(message)s', filemode='w')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    logger.info(f\"This is a summary of the run '{run_name}':\")\n",
    "    logger.info(f'Batch size for this run: {batch_size}')\n",
    "    logger.info(f'Size of original image: {pic_width}x{pic_width}')\n",
    "    logger.info(f'Number of patterns: {m_patterns} which is {prc_patterns}% of {pic_width}^2')\n",
    "    # logger.info(f'Number of gray levels in output image: {n_gray_levels}')\n",
    "\n",
    "    if TRAIN_BY == \"Vectors\":\n",
    "        logger.info(f\"lr_vector {lr_vector}, epochs_vector {epochs_vector}\")\n",
    "    else:\n",
    "        logger.info(f\"Initial lr: {initial_lr}, Division factor: {div_factor_lr},\\n\\t\\t\\\n",
    "                    {num_dif_lr} divisions with {n_epochs} epochs for each\")\n",
    "        \n",
    "    print_and_log_message(f\"Number of samples in train is {num_train_mnist}-mnist and {num_train_coco}-coco\", log_path)\n",
    "    print_and_log_message(f\"Number of samples in test is {num_test_mnist}-mnist and {num_test_coco}-coco\", log_path)\n",
    "\n",
    "    logger.info('*************************\\n\\n')\n",
    "    \n",
    "    # This code section is for storing the log in the bucket (and not only locally):\n",
    "    # storage_client = storage.Client()   # create a client to interact with Google Cloud Storage\n",
    "    # bucket = storage_client.get_bucket(\"our_train_test_data\")\n",
    "    # bucket.blob(log_path).upload_from_filename(log_path)   # upload the log file to the bucket\n",
    "    \n",
    "    return log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47470b0d-dc93-45be-9d21-9a76fa801c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_and_log_message(message, log_path):\n",
    "    logging.basicConfig(filename=log_path, format='%(asctime)s %(message)s', filemode='w')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.WARNING)\n",
    "\n",
    "    if type(message) == str:\n",
    "        # print(message)\n",
    "        logger.warning(message)\n",
    "    else:\n",
    "        logger.exception(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d51bd5-275e-43e6-a648-d59f39e1bcf7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Support Functions section:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee7642d0-b2f5-495a-a685-e51c9e10fb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_folder(net_name, num_samp_coco, num_samp_mnist, batch_size, n_gray_levels, prc_patterns):\n",
    "    folder_name = f'{net_name}_NumSamp_C{num_samp_coco}_M{num_samp_mnist}_bs_{batch_size}_prc{prc_patterns}'\n",
    "    print(folder_name)\n",
    "    folder_path = 'Results/' + folder_name\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")   # set the bucket\n",
    "    \n",
    "    # check if not[there are any files (blobs), in the folder]\n",
    "    if not any(bucket.list_blobs(prefix=folder_path)):\n",
    "        empty_blob = bucket.blob(folder_path + '/')  # create an empty blob with the folder prefix\n",
    "        empty_blob.upload_from_string('')            # upload an empty string as the content for the blob\n",
    "    return folder_path\n",
    "\n",
    "\n",
    "def save_img_to_bucket(img_path, img_array, n_gray_levels):\n",
    "    # initialize the Google Cloud Storage client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")\n",
    "    \n",
    "    # convert the image to PIL, and save to a byte buffer\n",
    "    # normalize the values to 0-240 (not 255 because of rounding)\n",
    "    img_array = (img_array * n_gray_levels).astype(np.uint8)\n",
    "    pil_image = Image.fromarray(img_array).convert('L')\n",
    "    byte_buffer = io.BytesIO()\n",
    "    pil_image.save(byte_buffer, format='JPEG')\n",
    "    \n",
    "    # create a blob object representing the image path in the bucket\n",
    "    blob = bucket.blob(img_path)\n",
    "\n",
    "    img_byts = img_array.astype(np.uint8).tobytes()   # convert the image array to bytes\n",
    "    blob.upload_from_string(byte_buffer.getvalue(), content_type='image/jpeg')\n",
    "    \n",
    "    \n",
    "# this function is not used\n",
    "def discretize(my_tensor, n_gray_levels):\n",
    "    \"\"\" change scale to n gray levels \"\"\"\n",
    "    tensor_0_to_1 = my_tensor / 255\n",
    "    disc_tensor = (tensor_0_to_1 * n_gray_levels).round()   # max is n_gray_levels\n",
    "    return disc_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9da9c-c467-493d-92b0-6ef4207e2f4e",
   "metadata": {},
   "source": [
    "**Histogram Equalization functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09f5d993-f8c5-483e-84bf-de44967bdcd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hist_equalization(image, n_gray_levels):\n",
    "    image_0 = image - image.min()                # min value becomes 0\n",
    "    image_0_255 = image_0 / image_0.max() * 255  # max value becomes 255\n",
    "    image_unit8 = image_0_255.to(torch.uint8)\n",
    "    \n",
    "    # calculate histogram on the GPU\n",
    "    histogram = torch.histc(image_unit8.float().view(-1), bins=256, min=0, max=255)\n",
    "    cdf = histogram.cumsum(0)\n",
    "    cdf = (cdf / cdf[-1]) * 255\n",
    "    \n",
    "    # perform histogram equalization\n",
    "    equalized_image = torch.gather(cdf, 0, image_unit8.view(-1).long())\n",
    "    equalized_image = equalized_image.view(image_unit8.size())\n",
    "    \n",
    "    # convert back to low_gray values and return as tensor, range is now 0-(255//n_gray_level)\n",
    "    equ_low_gray = torch.div(equalized_image, n_gray_levels, rounding_mode='trunc').to(torch.float32)\n",
    "    \n",
    "    return equ_low_gray\n",
    "\n",
    "\n",
    "def hist_equ_for_tensor(image_tensor, n_gray_levels):\n",
    "    dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    image_tensor = image_tensor.to(dev)\n",
    "    equ_reduced_tensor = torch.zeros_like(image_tensor, device=dev)\n",
    "    \n",
    "    for i, image in enumerate(image_tensor):\n",
    "        image = image.to(dev)\n",
    "        gray_reduced_image = hist_equalization(image[0], n_gray_levels)\n",
    "        equ_reduced_tensor[i][0] = gray_reduced_image\n",
    "    equ_reduced_tensor = equ_reduced_tensor.to(torch.float32)\n",
    "    equ_reduced_tensor = Variable(equ_reduced_tensor, requires_grad=True)\n",
    "    \n",
    "    return equ_reduced_tensor\n",
    "\n",
    "\n",
    "# this function is not used\n",
    "def display_hist_equ_results(image, equ, n_gray_levels):\n",
    "    res = np.hstack((image//n_gray_levels, equ//n_gray_levels))  # stacking images side-by-side\n",
    "    plt.imshow(res)\n",
    "\n",
    "    plt.hist(np.array(image.flatten())/n_gray_levels, n_gray_levels, [0, n_gray_levels], color='r')\n",
    "    plt.hist(np.array(equ.flatten())/n_gray_levels, n_gray_levels, [0, n_gray_levels], color='b')\n",
    "    plt.xlim([0, n_gray_levels])\n",
    "    plt.legend(('histogram before', 'histogram after'), loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da30a8c-8cc8-4619-b49e-fb74565370fe",
   "metadata": {},
   "source": [
    "**PSNR and SSIM calculations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f675bb-f3b0-4277-b8cc-cdde942995c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PSNR(image1, image2, m, n, max_i=255):\n",
    "    \"\"\" m = n = pic_width = 128,   max_i = n_gray_levels = 30 \"\"\"\n",
    "    dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    y = torch.add(image1.to(dev), (-image2).to(dev))\n",
    "    y2 = torch.pow(y, 2)\n",
    "    mse = torch.sum(y2) / (m * n)\n",
    "    psnr = 10 * math.log(max_i/mse, 10)\n",
    "    return psnr\n",
    "\n",
    "\n",
    "def SSIM(image1, image2):\n",
    "    c1, c2 = 0.01, 0.03   # constant for numerical stability\n",
    "    window_size = 11      # window size for SSIM calculation\n",
    "    \n",
    "    image1 = image1.unsqueeze(0)\n",
    "    image2 = image2.unsqueeze(0)\n",
    "\n",
    "    mu1 = F.avg_pool2d(image1, window_size, 1, window_size // 2, count_include_pad=False).squeeze(0)\n",
    "    mu2 = F.avg_pool2d(image2, window_size, 1, window_size // 2, count_include_pad=False).squeeze(0)\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.avg_pool2d(image1 * image1, window_size, 1, window_size // 2, count_include_pad=False).squeeze(0) - mu1_sq\n",
    "    sigma2_sq = F.avg_pool2d(image2 * image2, window_size, 1, window_size // 2, count_include_pad=False).squeeze(0) - mu2_sq\n",
    "    sigma12 = F.avg_pool2d(image1 * image2, window_size, 1, window_size // 2, count_include_pad=False).squeeze(0) - mu1_mu2\n",
    "\n",
    "    numerator = (2 * mu1_mu2 + c1) * (2 * sigma12 + c2)\n",
    "    denominator = (mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2)\n",
    "    ssim_map = numerator / denominator\n",
    "\n",
    "    ssim = ssim_map.mean().item()\n",
    "    return ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c83c89-8e54-4111-8317-959eef13a560",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Training section**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3a7d6-670b-4922-8f2a-c570ab1a0572",
   "metadata": {},
   "source": [
    "**Save Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d68bb62-c372-47cb-b9f9-d4beb1aaa0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_output_images_vs_original(low_gray_output, output, y_label, pic_width, folder_path, name_sub_folder, n_gray_levels):\n",
    "    dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    low_gray_output = low_gray_output.to(dev)\n",
    "    output = output.to(dev)\n",
    "    y_label = y_label.to(dev)\n",
    "\n",
    "    in_out_images = zip(low_gray_output.view(-1, pic_width, pic_width),\n",
    "                        output.view(-1, pic_width, pic_width),\n",
    "                        y_label.view(-1, pic_width, pic_width))\n",
    "    \n",
    "    images_dir = folder_path + '/' + name_sub_folder\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")   # set the bucket\n",
    "    \n",
    "    if not any(bucket.list_blobs(prefix=images_dir)):\n",
    "        empty_blob = bucket.blob(images_dir + '/')  # create an empty blob with the folder prefix\n",
    "        empty_blob.upload_from_string('')           # upload an empty string as the content for the blob        \n",
    "        \n",
    "    for i, (low_gray_image, out_image, orig_image) in enumerate(in_out_images):\n",
    "        # fig, ax = plt.subplots(2)\n",
    "        # ax[0].imshow(out_image.detach().numpy())\n",
    "        # ax[1].imshow(orig_image.cpu().detach().numpy())\n",
    "        save_img_to_bucket(images_dir + f'/train_image_{i}_low_gray_out.jpeg',\n",
    "                           low_gray_image.detach().cpu().numpy(), n_gray_levels)\n",
    "        save_img_to_bucket(images_dir + f'/train_image_{i}_out.jpeg',\n",
    "                           out_image.detach().cpu().numpy(), n_gray_levels)\n",
    "        save_img_to_bucket(images_dir + f'/train_image_{i}_orig.jpeg',\n",
    "                           orig_image.cpu().detach().cpu().numpy(), n_gray_levels)\n",
    "\n",
    "        if i == 0:\n",
    "            heq_out = wandb.Image(low_gray_image)\n",
    "        if i > 29:\n",
    "            break\n",
    "\n",
    "        return heq_out\n",
    "\n",
    "\n",
    "# TODO: fix this function to save to bucket instead of locally, then uncomment it everywhere\n",
    "def save_psnr_and_Loss_functions(loss_func, psnr_func, folder_path):\n",
    "    with open(folder_path + '/Loss_training', \"wb\") as output_file:\n",
    "        pickle.dump(loss_func, output_file)\n",
    "    with open(folder_path + '/PSNR_training', \"wb\") as output_file:\n",
    "        pickle.dump(psnr_func, output_file)\n",
    "\n",
    "\n",
    "def save_outputs(low_gray_output, output, y_label, pic_width, folder_path, name_sub_folder,\n",
    "                 loss_func, psnr_func, n_gray_levels):\n",
    "    heq_out = save_output_images_vs_original(low_gray_output, output, y_label, pic_width,\n",
    "                                             folder_path, name_sub_folder, n_gray_levels)\n",
    "    # save_psnr_and_Loss_functions(loss_func, psnr_func, folder_path)\n",
    "\n",
    "    return heq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9560be44-7044-4ca4-b8d5-dc60e5b0a022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_training_messages(epoch, train_loss, avg_psnr, avg_ssim, start, log_path):\n",
    "    end = time.time()\n",
    "    print_and_log_message(f'Epoch: {epoch + 1} \\tTraining Loss: {train_loss:.6f}', log_path)\n",
    "    print_and_log_message(f\"Time for epoch {epoch + 1} : {round(end - start)} sec\", log_path)\n",
    "    print_and_log_message(f'Average PSNR for epoch {epoch + 1} on training set is {avg_psnr:.6f}', log_path)\n",
    "    print_and_log_message(f'Average SSIM for epoch {epoch + 1} on training set is {avg_ssim:.6f}', log_path)\n",
    "    \n",
    "\n",
    "def avg_calc(sum_psnr, sum_ssim, train_loss, num_samples):\n",
    "    avg_psnr = sum_psnr / num_samples\n",
    "    avg_ssim = sum_ssim / num_samples\n",
    "    train_loss = train_loss / num_samples\n",
    "    return avg_psnr, avg_ssim, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ba9ae-4a50-4f12-aa31-281e39e009fc",
   "metadata": {},
   "source": [
    "**Train functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91d7e75d-5c64-44b6-af5d-cc718a005c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_parameters(initial_lr, num_dif_lr, div_factor_lr, train_loader, criterion, batch_size, n_epochs, pic_width,\n",
    "                        log_path, n_gray_levels, folder_path, model):\n",
    "    \n",
    "    storage_client = storage.Client()   # create a client to interact with Google Cloud Storage\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")\n",
    "    \n",
    "    lr_i = initial_lr\n",
    "    for i in range(num_dif_lr):\n",
    "        print_and_log_message(f'learning rate: {lr_i}', log_path)\n",
    "        # bucket.blob(log_path).upload_from_filename(log_path)   # update the log file for each lr, if saved to bucket\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr_i)\n",
    "        model, optimizer = train_net(model, train_loader, criterion, optimizer, batch_size, n_epochs, pic_width,\n",
    "                                     log_path, n_gray_levels, lr_i, folder_path,  name_sub_folder='train_images')\n",
    "        lr_i = lr_i / div_factor_lr\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_by_vectors(lr_vector, epochs_vector,  train_loader, criterion, batch_size, pic_width,\n",
    "                     log_path, n_gray_levels, folder_path, model):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")\n",
    "    \n",
    "    for lr_i, n_epochs in zip(lr_vector, epochs_vector):\n",
    "        print_and_log_message(f'learning rate: {lr_i}', log_path)\n",
    "        # bucket.blob(log_path).upload_from_filename(log_path)   # update the log file for each lr, if saved to bucket\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr_i)\n",
    "        model, optimizer = train_net(model, train_loader, criterion, optimizer, batch_size, n_epochs, pic_width,\n",
    "                                     log_path, n_gray_levels, lr_i, folder_path,  name_sub_folder='train_images')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_net(model, train_loader, criterion, optimizer, batch_size, n_epochs, pic_width, log_path, n_gray_levels,\n",
    "              curr_lr, folder_path, name_sub_folder, training=1):\n",
    "    \"\"\" train the network by the model.\n",
    "        n_epochs - number of times the NN see all the train data \"\"\"\n",
    "    model.train()\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    num_samples = len(train_loader.dataset)\n",
    "    loss_func, psnr_func = [], []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()   # start measuring time for epoch\n",
    "        train_loss, sum_psnr, sum_ssim = 0.0, 0.0, 0.0\n",
    "        for x_data, y_label in train_loader:\n",
    "            low_gray_output, output, optimizer, loss_func, sum_psnr, sum_ssim, psnr_func, train_loss = \\\n",
    "                train_batch(model, x_data, y_label, optimizer, pic_width, loss_func, train_loss,\n",
    "                            sum_psnr, sum_ssim, psnr_func, n_gray_levels, criterion, training)\n",
    "        avg_psnr, avg_ssim, train_loss = avg_calc(sum_psnr, sum_ssim, train_loss, num_samples)\n",
    "        print_training_messages(epoch, train_loss, avg_psnr, avg_ssim, start, log_path)\n",
    "        heq_out = save_outputs(low_gray_output, output, y_label, pic_width, folder_path, name_sub_folder,\n",
    "                               loss_func, psnr_func, n_gray_levels)\n",
    "\n",
    "        # log current values to W&B\n",
    "        wandb.log({\"loss\": train_loss, \"PSNR\": avg_psnr, \"SSIM\": avg_ssim, \"HEQ-output\": heq_out})\n",
    "\n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "def train_batch(model, x_data, y_label, optimizer, pic_width, loss_func, train_loss, sum_psnr, sum_ssim, psnr_func,\n",
    "                n_gray_levels, criterion, training):\n",
    "    dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    x_data, y_label = x_data.to(dev), y_label.to(dev)\n",
    "    y_label = y_label.to(torch.float32)\n",
    "    optimizer.zero_grad()    # clear the gradients of all optimized variables\n",
    "    output = model(x_data)   # forward pass: compute predictions\n",
    "    low_gray_output = hist_equ_for_tensor(output, n_gray_levels)\n",
    "    \n",
    "    # calculate the loss\n",
    "    loss = criterion(low_gray_output.view(-1, 1, pic_width, pic_width), y_label.view(-1, 1, pic_width, pic_width))\n",
    "    \n",
    "    if training:\n",
    "        loss.backward()      # backward pass: compute gradient of the loss\n",
    "        optimizer.step()     # parameter update - perform a single optimization step\n",
    "    train_loss += loss.item() * x_data.size(0)        # update running training loss\n",
    "    loss_func.append(loss.item() * x_data.size(0))\n",
    "\n",
    "    in_out_images = zip(low_gray_output.view(-1, pic_width, pic_width), y_label.view(-1, pic_width, pic_width))\n",
    "    temp_sum_psnr = 0\n",
    "    temp_sum_ssim = 0\n",
    "    for out_image, orig_image in in_out_images:\n",
    "        temp_sum_psnr += PSNR(out_image, orig_image, pic_width, pic_width, n_gray_levels)\n",
    "        temp_sum_ssim += SSIM(out_image, orig_image)\n",
    "\n",
    "    psnr_func.append(temp_sum_psnr / x_data.size(0))  # per batch size in epoch\n",
    "    sum_psnr += temp_sum_psnr\n",
    "    sum_ssim += temp_sum_ssim\n",
    "\n",
    "    return low_gray_output, output, optimizer, loss_func, sum_psnr, sum_ssim, psnr_func, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d430e3-9ba6-4869-823f-7e445b5e0fb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Testing section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "026db7e1-e5ff-46b1-ac0b-b1428bc59a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_testing_messages(test_loss, num_samples, avg_psnr, avg_ssim, log_path):\n",
    "    print_and_log_message(f'Avarge PSNR for {num_samples} images in test set is {avg_psnr}', log_path)\n",
    "    print_and_log_message(f'Avarge SSIM for {num_samples} images in test set is {avg_ssim}', log_path)\n",
    "    print_and_log_message('Test Loss: {:.6f}\\n'.format(test_loss), log_path)\n",
    "\n",
    "    \n",
    "def save_test_outputs(output, y_label, pic_width, folder_path, name_sub_folder, n_gray_levels):\n",
    "    dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    output = output.to(dev)\n",
    "    y_label = y_label.to(dev)\n",
    "\n",
    "    in_out_images = zip(output.view(-1, pic_width, pic_width), y_label.view(-1, pic_width, pic_width))\n",
    "    images_dir = folder_path + '/' + name_sub_folder\n",
    "    \n",
    "    storage_client = storage.Client()   # create a client to interact with Google Cloud Storage\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")   # set the bucket\n",
    "    \n",
    "    if not any(bucket.list_blobs(prefix=images_dir)):\n",
    "        empty_blob = bucket.blob(images_dir + '/')   # create an empty blob with the folder prefix\n",
    "        empty_blob.upload_from_string('')            # upload an empty string as the content for the blob\n",
    "    \n",
    "    for i, (out_image, orig_image) in enumerate(in_out_images):\n",
    "        save_img_to_bucket(images_dir + f'/test_image_{i}_out.jpeg', out_image.detach().cpu().numpy(), n_gray_levels)\n",
    "        save_img_to_bucket(images_dir + f'/test_image_{i}_orig.jpeg', orig_image.detach().cpu().numpy(), n_gray_levels)\n",
    "        if i > 18:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0718a623-2456-4d3e-bc27-50841fbe0b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_net(model, test_loader, criterion, batch_size, pic_width, log_path, n_gray_levels, folder_path,\n",
    "             name_sub_folder='test_images'):\n",
    "    test_loss, sum_psnr, sum_ssim = 0.0, 0.0, 0.0\n",
    "    num_samples = len(test_loader.dataset)\n",
    "    model.eval()\n",
    "    for x_data, y_label in test_loader:\n",
    "        output, test_loss, sum_psnr, sum_ssim = test_batch(model, x_data, y_label, pic_width, test_loss, sum_psnr,\n",
    "                                                           sum_ssim, n_gray_levels, criterion)\n",
    "    avg_psnr, avg_ssim, train_loss = avg_calc(sum_psnr, sum_ssim, test_loss, num_samples)\n",
    "    print_testing_messages(test_loss, num_samples, avg_psnr, avg_ssim, log_path)\n",
    "    save_test_outputs(output, y_label, pic_width, folder_path, name_sub_folder, n_gray_levels)\n",
    "\n",
    "\n",
    "def test_batch(model, x_data, y_label, pic_width, test_loss, sum_psnr, sum_ssim, n_gray_levels, criterion):\n",
    "    dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    x_data, y_label = x_data.to(dev), y_label.to(dev).to(torch.float32)\n",
    "    output = model(x_data)\n",
    "    # disc_output = discretize(output, n_gray_levels)\n",
    "    loss = criterion(output.view(-1, 1, pic_width, pic_width),\n",
    "                     y_label.view(-1, 1, pic_width, pic_width))  # calculate the loss\n",
    "    test_loss += loss.item() * x_data.size(0)                    # update test loss\n",
    "\n",
    "    in_out_images = zip(output.view(-1, pic_width, pic_width), y_label.view(-1, pic_width, pic_width))\n",
    "    for out_image, orig_image in in_out_images:\n",
    "        sum_psnr += PSNR(out_image, orig_image, pic_width, pic_width, n_gray_levels)\n",
    "        sum_ssim += SSIM(out_image, orig_image)\n",
    "\n",
    "    return output, test_loss, sum_psnr, sum_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f2b27-4c05-4ce7-9a19-57f94a60be60",
   "metadata": {},
   "source": [
    "### **Parameters section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d5ae73e-8727-4c8f-8140-b15af036f6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_run_parameters():\n",
    "    batch_size = 90\n",
    "    pic_width = 128\n",
    "    prc_patterns = 60\n",
    "    n_gray_levels = 30\n",
    "    m_patterns = (pic_width ** 2) * prc_patterns // 100\n",
    "\n",
    "    # for train_by_params\n",
    "    initial_lr = 10 ** -3\n",
    "    num_dif_lr = 3\n",
    "    div_factor_lr = 100\n",
    "    n_epochs = 250   # per learning rate\n",
    "    \n",
    "    # for train_by_vectors\n",
    "    lr_vector = [10 ** -3, 10 ** -4, 10 ** -6]\n",
    "    epochs_vector = [50, 10, 140]\n",
    "\n",
    "    input_shape = (pic_width, pic_width, batch_size)\n",
    "    data_sets = ['mnist', 'coco']   # optional values: 'mnist', 'coco', 'div2k'\n",
    "    \n",
    "    # use 20000-50 coco, 5000-700 mnist for sweep\n",
    "    train_samples_coco, test_samples_coco = (20000, 10) if 'coco' in data_sets else (0, 0)      # maximum 102995 train, 50 test\n",
    "    train_samples_mnist, test_samples_mnist = (10000, 10) if 'mnist' in data_sets else (0, 0)   # maximum 60000 train, 10000 test\n",
    "    \n",
    "    generate = True        # to generate even if loaders exist\n",
    "    TRAIN_BY = \"Params\"    # \"Params\" for train_by_parameters, \"Vectors\" for train_by_vectors\n",
    "\n",
    "    return batch_size, pic_width, prc_patterns, n_gray_levels, m_patterns, initial_lr, div_factor_lr, num_dif_lr, \\\n",
    "           n_epochs, train_samples_coco, test_samples_coco, train_samples_mnist, test_samples_mnist, input_shape, \\\n",
    "           lr_vector, epochs_vector, data_sets, generate, TRAIN_BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838476f0-dfd1-4dbc-b91d-51d2fcea89b1",
   "metadata": {},
   "source": [
    "### **Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88b421b7-5445-4cd2-96b9-2953b7d79154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize Parameters\n",
    "    batch_size, pic_width, prc_patterns, n_gray_levels, m_patterns, initial_lr, div_factor_lr, \\\n",
    "        num_dif_lr, n_epochs, train_samples_coco, test_samples_coco, train_samples_mnist, test_samples_mnist, \\\n",
    "        input_shape, lr_vector, epochs_vector, data_sets, generate, TRAIN_BY = get_run_parameters()\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"DattNet\",\n",
    "        tags=[f\"by{TRAIN_BY}\"],\n",
    "\n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "            # Variables for BY_VECTORS run\n",
    "            # \"lr_vector\": lr_vector,\n",
    "            # \"epochs_vec\": epochs_vector,\n",
    "\n",
    "            # Variables for BY_PARAMS run\n",
    "            \"init_lr\": initial_lr,\n",
    "            \"num_of_lr\": num_dif_lr,\n",
    "            \"div_f_lr\": div_factor_lr,\n",
    "            \"epochs_for_lr\": n_epochs,\n",
    "\n",
    "            \"batch_size\": batch_size,\n",
    "            \"prc_patterns\": prc_patterns,\n",
    "            \"train_num_coco\": train_samples_coco,\n",
    "            \"train_num_mnist\": train_samples_mnist\n",
    "        })\n",
    "\n",
    "    # Set sweep values for the hyperparameters\n",
    "    # lr_vector = wandb.config.lr_vector\n",
    "    # epochs_vector = wandb.config.epochs_vec\n",
    "    initial_lr = wandb.config.init_lr\n",
    "    num_dif_lr = wandb.config.num_of_lr\n",
    "    div_factor_lr = wandb.config.div_f_lr\n",
    "    n_epochs = wandb.config.epochs_for_lr\n",
    "    batch_size = wandb.config.batch_size\n",
    "    prc_patterns = wandb.config.prc_patterns\n",
    "    train_samples_coco = wandb.config.train_num_coco\n",
    "    train_samples_mnist = wandb.config.train_num_mnist\n",
    "    \n",
    "    dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(dev)\n",
    "\n",
    "    folder_path = make_folder('DattNet', train_samples_coco, train_samples_mnist, batch_size, n_gray_levels, prc_patterns)\n",
    "    log_path = print_run_info_to_log(batch_size, pic_width, prc_patterns, n_gray_levels, m_patterns, initial_lr,\n",
    "                                     div_factor_lr, num_dif_lr, n_epochs, train_samples_coco, train_samples_mnist,\n",
    "                                     test_samples_coco, test_samples_mnist, lr_vector, epochs_vector, run.name, TRAIN_BY)\n",
    "    \n",
    "    try:   # get data\n",
    "        train_loader, test_loader, data_time_message, patterns = get_data(generate, log_path, batch_size, pic_width, prc_patterns,\n",
    "                                                                          m_patterns, train_samples_coco, train_samples_mnist,\n",
    "                                                                          test_samples_coco, test_samples_mnist, n_gray_levels, data_sets)\n",
    "        print_and_log_message(data_time_message, log_path)\n",
    "        wandb.alert(title=\"Data Generated\", text=\"Finished loading/generating the data successfully\", level=wandb.AlertLevel.INFO)\n",
    "    except Exception as Argument:\n",
    "        print_and_log_message(Argument, log_path)\n",
    "        wandb.alert(title=\"Failed to get the Data!\", text=str(Argument), level=wandb.AlertLevel.ERROR)\n",
    "        return      # stop the run after the error\n",
    "\n",
    "    # define Model and Loss\n",
    "    model = DattNet(pic_width, m_patterns, input_shape)\n",
    "    model.to(dev)\n",
    "    criterion = nn.MSELoss()\n",
    "    model_path = folder_path + '/model.pth'\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(\"our_train_test_data\")   # set the bucket\n",
    "\n",
    "    try:\n",
    "        # Load past model if exists\n",
    "        # if exists(model_path) and not generate:\n",
    "        #     model.load_state_dict(torch.load(model_path))     # load saved model\n",
    "        # else:\n",
    "\n",
    "        if TRAIN_BY == \"Vectors\":\n",
    "            model = train_by_vectors(lr_vector, epochs_vector, train_loader, criterion, batch_size,\n",
    "                                     pic_width, log_path, n_gray_levels, folder_path, model)\n",
    "        else:\n",
    "            model = train_by_parameters(initial_lr, num_dif_lr, div_factor_lr,  train_loader, criterion, batch_size,\n",
    "                                        n_epochs, pic_width, log_path, n_gray_levels, folder_path, model)\n",
    "\n",
    "        # torch.save(model.state_dict(), model_path)    # TODO: fix saving Model to bucket instead of locally\n",
    "    except Exception as Argument:\n",
    "        print_and_log_message(Argument, log_path)\n",
    "        wandb.alert(title=\"Run Crashed during Training!\", text=str(Argument), level=wandb.AlertLevel.ERROR)\n",
    "        # bucket.blob(log_path).upload_from_filename(log_path)   # update the log file in the end\n",
    "        return     # stop the run after the error\n",
    "\n",
    "    test_net(model, test_loader, criterion, batch_size, pic_width, log_path, n_gray_levels, folder_path)\n",
    "    \n",
    "    wandb.alert(title=\"Run Finished!\", text=\"Miracles Happen :)\", level=wandb.AlertLevel.INFO)\n",
    "    wandb.finish()\n",
    "    \n",
    "    #bucket.blob(log_path).upload_from_filename(log_path)   # update the log file in the end, if saved to bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f831cbf-3744-4726-ac3e-8209ec081c22",
   "metadata": {},
   "source": [
    "**Run main with if, or wandb agent for sweep:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c86ef-7e58-4e70-a27d-e14aee43486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "wandb.agent(sweep_id=\"noaavra/DattNet/x2w9ltj4\", function=main, count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a71e95-a7bd-4afd-938a-c03d17140f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu113.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu113:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
